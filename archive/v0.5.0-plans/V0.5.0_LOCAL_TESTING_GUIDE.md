# v0.5.0 Local Testing Guide

**Version:** v0.5.0 Phase 1 Pilot
**Date:** 2025-10-30
**Status:** ✅ Ready for Local Testing

---

## Overview

This guide walks you through testing v0.5.0 verification + code generation features locally before deploying to DigitalOcean production.

**What's New in v0.5.0:**
- ✅ **Verification System** (179 tests passing, 77% coverage)
- ✅ **Code Generation** (Template-based, linted, sandboxed)
- ⏳ **Integration Tests** (Need fixes - see Known Issues)

---

## Prerequisites

**Required:**
- Docker Desktop running
- ~10GB disk space
- 2-3 hours for full testing

**API Keys Needed:**
- HusanAI key (already in .env.local.example)
- Official Anthropic API key (fallback)
- Supabase keys (optional - only for operations_assistant + menu_engineer)

---

## Quick Start (Automated)

### Step 1: Run Setup Script (15 minutes)

```bash
cd /Users/heng/Development/campfire
./setup-local-dev.sh
```

**This script:**
1. Creates `.env.local` from template
2. Creates storage directories
3. Builds Docker images (~5-10 minutes)
4. Initializes Campfire database
5. Provides next steps

**When prompted:**
- Edit `ai-bot/.env.local`
- Add your fallback API key: `ANTHROPIC_API_KEY_FALLBACK=sk-ant-api03-YOUR_KEY`

### Step 2: Create Bot Users (5 minutes)

```bash
# Open Rails console
docker-compose -f docker-compose.dev.yml run --rm campfire bin/rails console
```

**Paste this code in console:**

```ruby
bots = [
  {name: "财务分析师", id: "financial_analyst"},
  {name: "技术助手", id: "technical_assistant"},
  {name: "个人助手", id: "personal_assistant"},
  {name: "日报助手", id: "briefing_assistant"},
  {name: "AI Assistant", id: "default"},
  {name: "运营数据助手", id: "operations_assistant"},
  {name: "Claude Code导师", id: "cc_tutor"},
  {name: "菜单工程师", id: "menu_engineer"}
]

bots.each do |b|
  bot = User.create!(name: b[:name], email: "#{b[:id]}@bots.local", password: "dev123", role: "bot")
  puts "#{b[:name]}: #{bot.id}-#{bot.bot_token}"
end
```

**Save the output!** You'll need these bot keys.

### Step 3: Update Bot Configurations (5 minutes)

Copy bot keys from console output and update JSON files:

```bash
# Example: personal_assistant bot key is "4-GZfqGLxdULBM"
nano ai-bot/bots/personal_assistant.json

# Update "bot_key" field with your local bot key
```

**Files to update:**
- `ai-bot/bots/financial_analyst.json`
- `ai-bot/bots/technical_assistant.json`
- `ai-bot/bots/personal_assistant.json`
- `ai-bot/bots/briefing_assistant.json`
- `ai-bot/bots/default.json`
- `ai-bot/bots/operations_assistant.json`
- `ai-bot/bots/cc_tutor.json`
- `ai-bot/bots/menu_engineer.json`

### Step 4: Start Services (2 minutes)

```bash
cd /Users/heng/Development/campfire
docker-compose -f docker-compose.dev.yml up
```

**Wait for health checks:**
- ✅ Campfire: http://localhost:3000/up
- ✅ AI Bot: http://localhost:8000/health

**Expected output:**
```
campfire-dev          | * Listening on http://0.0.0.0:80
campfire-ai-bot-dev   | INFO:     Uvicorn running on http://0.0.0.0:8000
```

### Step 5: Access Campfire (1 minute)

Open browser: http://localhost:3000

**Login credentials:**
- Email: `admin@example.com`
- Password: `password`

---

## v0.5.0 Test Scenarios

### Test 1: Verification Catches Calculation Errors (5 min)

**Goal:** Verify that verification system catches impossible calculations

**Steps:**
1. Open Campfire at http://localhost:3000
2. Create new room or use existing room
3. @mention personal_assistant: "@个人助手 Calculate profit margin: Revenue $100, Cost $120"
4. Observe response

**Expected Result:**
- ⚠️ Verification warning: "Impossible margin: cost exceeds revenue"
- Bot suggests checking inputs
- No crash or error

**What This Tests:**
- Input validation working
- Financial verification rules active
- Warn-first approach (doesn't block, just warns)

---

### Test 2: Code Generation with Templates (10 min)

**Goal:** Verify template-based code generation works

**Steps:**
1. @mention personal_assistant: "@个人助手 Generate Python code to analyze this data: [1,2,3,4,5]"
2. Wait for response

**Expected Result:**
- Bot generates Python code using template
- Code passes ruff linting
- Code passes mypy type checking
- Bot offers to execute code (sandboxed)
- If executed, shows output

**What This Tests:**
- Code generation templates working
- Linting integration (ruff + mypy)
- Sandboxed execution via Bash tool
- Safe execution patterns

---

### Test 3: PDF Document Processing (5 min)

**Goal:** Verify PDF processing still works with v0.5.0

**Steps:**
1. Upload a PDF file to Campfire room
2. @mention personal_assistant: "@个人助手 请分析这个PDF文件"
3. Wait for response

**Expected Result:**
- Bot extracts text from PDF
- Bot provides summary and analysis
- No errors

**What This Tests:**
- Read tool PDF support
- Document processing workflow
- v0.5.0 doesn't break existing features

---

### Test 4: Multi-Step Workflow with Verification (10 min)

**Goal:** Test verification in complex workflows

**Steps:**
1. @mention personal_assistant: "@个人助手 Create task 'Review Q4 financials', set reminder tomorrow 9am, calculate ROI: Revenue 1000, Cost 800"
2. Wait for response

**Expected Result:**
- Task created successfully
- Reminder set for tomorrow 9am
- ROI calculated correctly (25%)
- Verification confirms calculations
- All operations complete

**What This Tests:**
- Multi-tool coordination
- Verification doesn't block normal operations
- Task management still works
- Calculations verified

---

### Test 5: HTML Presentation Generation (10 min)

**Goal:** Test HTML output with visual verification

**Steps:**
1. @mention personal_assistant: "@个人助手 Create an HTML presentation about v0.5.0 testing"
2. Wait for response

**Expected Result:**
- Bot generates HTML presentation
- HTML structure verified (proper tags, UTF-8, responsive)
- Visual verification passes
- Presentation displays correctly in browser

**What This Tests:**
- HTML generation with verification
- Visual verification rules
- Presentation quality checks
- No token bloat from verification

---

## Monitoring During Tests

### Watch Logs in Real-Time

```bash
# In separate terminal
docker-compose -f docker-compose.dev.yml logs -f ai-bot
```

**Look for:**
- ✅ `[VERIFICATION]` log entries (validation working)
- ✅ `[CODEGEN]` log entries (code generation working)
- ❌ Any Python exceptions (bugs)
- ❌ High latency (>10s response times)

### Check Performance

**Before v0.5.0 (baseline):**
- Typical response: 3-5 seconds
- Complex workflows: 5-10 seconds

**After v0.5.0 (target):**
- Typical response: <6 seconds (+20% acceptable)
- Complex workflows: <11 seconds (+10% acceptable)
- **Gate:** ≤10% latency increase

### Check Database

```bash
# Access SQLite database
sqlite3 storage/db/production.sqlite3

# Recent messages
SELECT COUNT(*) FROM messages WHERE created_at > datetime('now', '-1 hour');

# Bot activity
SELECT u.name, COUNT(m.id) as message_count
FROM users u
LEFT JOIN messages m ON u.id = m.creator_id
WHERE u.role = 1
GROUP BY u.id;
```

---

## Test Results Documentation

### Create Test Report

After completing all 5 tests, document results:

```markdown
# v0.5.0 Local Testing Results

**Date:** [YYYY-MM-DD]
**Tester:** [Your name]
**Duration:** [Total time]

## Test Results Summary

| Test | Status | Notes |
|------|--------|-------|
| 1. Verification catches errors | ✅/❌ | [Details] |
| 2. Code generation works | ✅/❌ | [Details] |
| 3. PDF processing works | ✅/❌ | [Details] |
| 4. Multi-step workflow | ✅/❌ | [Details] |
| 5. HTML presentation | ✅/❌ | [Details] |

## Performance Observations

- Average response time: [X] seconds
- Peak response time: [X] seconds
- Latency increase vs. v0.4.0.2: [X]%

## Issues Found

1. [Issue description]
2. [Issue description]

## Validation Gates Status

- [ ] Verification catches ≥1 calculation error
- [ ] Code generation used successfully ≥2 times
- [ ] All document processing works (PDF, images)
- [ ] No critical errors in logs
- [ ] Response time <10s for typical requests

## Recommendation

- [ ] **Deploy to production** - All gates passed
- [ ] **Fix issues first** - [List issues to fix]
- [ ] **Need more testing** - [Specify what to test]
```

---

## Known Issues

### Issue 1: Integration Tests Import Errors

**Status:** Known, needs fix
**Impact:** Does not affect functionality, only test coverage

**Details:**
```
ImportError: cannot import name 'verify_profit_margin' from 'src.verification'
```

**Tests Affected:**
- `tests/agent_behaviors/test_verification_integration.py`
- `tests/agent_behaviors/test_codegen_integration.py`
- `tests/agent_behaviors/test_pilot_critical_paths.py`

**Workaround:**
- Run unit tests only: `uv run pytest tests/verification/ -v`
- All 179 verification unit tests pass ✅

**Fix Required:**
- Update integration tests to match actual module exports
- Estimated time: 1-2 hours

### Issue 2: pytest-asyncio Warnings

**Status:** Known, cosmetic only
**Impact:** None (warnings only, tests still pass)

**Details:**
```
PytestUnknownMarkWarning: Unknown pytest.mark.asyncio
```

**Fix Required:**
- Add pytest-asyncio to pyproject.toml dependencies
- Configure pytest markers in pyproject.toml

---

## Troubleshooting

### Problem: "Cannot connect to Docker daemon"

**Solution:**
```bash
# Start Docker Desktop
open -a Docker

# Wait 30 seconds for Docker to start
# Then retry docker-compose command
```

### Problem: "Port 3000 already in use"

**Solution:**
```bash
# Find process using port 3000
lsof -ti:3000

# Kill process
kill -9 $(lsof -ti:3000)

# Retry docker-compose up
```

### Problem: "Bot not responding in Campfire"

**Check:**
1. AI Bot health: `curl http://localhost:8000/health`
2. Bot keys match between Campfire DB and JSON configs
3. Webhook connectivity: Check docker logs

**Debug:**
```bash
# Check AI bot logs
docker-compose -f docker-compose.dev.yml logs ai-bot

# Test webhook manually
curl -X POST http://localhost:8000/webhook/personal_assistant \
  -H "Content-Type: application/json" \
  -d '{"creator":{"id":1,"name":"Test"},"room":{"id":1,"name":"Test"},"content":"你好"}'
```

### Problem: "Database is locked"

**Solution:**
```bash
# Stop all services
docker-compose -f docker-compose.dev.yml down

# Remove lock file
rm storage/db/production.sqlite3-wal
rm storage/db/production.sqlite3-shm

# Restart services
docker-compose -f docker-compose.dev.yml up
```

---

## Next Steps After Local Testing

### If All Tests Pass ✅

**Action:** Deploy to DigitalOcean for 1-week pilot

**Steps:**
1. Build production image: `docker buildx build --platform linux/amd64 -t hengwoo/campfire-ai-bot:0.5.0-pilot .`
2. Push to Docker Hub: `docker push hengwoo/campfire-ai-bot:0.5.0-pilot`
3. Deploy via GitHub Actions or SSH
4. Monitor production for 1 week
5. Validate 5 success gates (see CLAUDE.md)

### If Issues Found ❌

**Action:** Fix issues locally, retest, then deploy

**Steps:**
1. Document all issues found
2. Create GitHub issues or fix locally
3. Run tests again after fixes
4. Repeat until all gates pass

---

## File Locations Reference

**Local Environment:**
```
/Users/heng/Development/campfire/
├── docker-compose.dev.yml        # Local Docker config
├── setup-local-dev.sh            # Automated setup
├── storage/
│   ├── db/production.sqlite3     # Local Campfire database
│   └── files/                    # Uploaded files
├── log/                          # Campfire logs
└── ai-bot/
    ├── .env.local                # Local API keys (not in git)
    ├── bots/*.json               # Bot configurations
    ├── src/verification/         # Verification module ✅
    ├── src/codegen/              # Code generation module ✅
    ├── tests/verification/       # 179 tests passing ✅
    └── session_cache/            # Session cache
```

**Production Environment (for reference):**
```
/root/ai-service/                 # DigitalOcean server
/root/ai-knowledge/               # Knowledge base
/var/once/campfire/               # Production Campfire
```

---

## v0.5.0 Architecture Summary

### Verification Module (2,205 lines, 77% coverage)

**Three-Layer Architecture:**
1. **Layer 1: Rules-based validation**
   - Input validation (types, ranges, required fields)
   - Business logic verification (financial equations, date ranges)
   - Data quality checks (missing fields, duplicates)

2. **Layer 2: Visual feedback**
   - HTML structure verification
   - Document formatting checks
   - Chart/graph quality validation

3. **Layer 3: LLM-as-judge** (Phase 2)
   - Secondary model evaluation
   - Quality scoring (1-5 scale)
   - Actionability assessment

**Files:**
- `src/verification/validators.py` - Input validation
- `src/verification/calculators.py` - Safe math operations
- `src/verification/verifiers.py` - Result verification
- `src/verification/formatters.py` - Output formatting
- `src/verification/visual_verifiers.py` - Visual checks
- `src/verification/config.py` - Per-bot configuration

### Code Generation Module (1,691 lines, 80% coverage)

**Template-Based Safe Generation:**
- Python data analysis (pandas, numpy)
- SQL queries (read-only)
- Financial calculations
- Operations analytics

**Linting Integration:**
- ruff: Style checking (PEP 8)
- mypy: Type checking
- Automatic fixes when possible

**Safe Execution:**
- Docker sandbox via Bash tool
- 30-second timeout
- Read-only operations
- Audit trail

**Files:**
- `src/codegen/templates.py` - Code templates
- `src/codegen/generators.py` - Generation logic
- `src/codegen/validators.py` - Linting integration
- `src/codegen/executor.py` - Safe execution

---

## Summary Checklist

**Before Testing:**
- [ ] Docker Desktop running
- [ ] API keys in `.env.local`
- [ ] Storage directories created
- [ ] Docker images built
- [ ] Bot users created in Campfire
- [ ] Bot keys updated in JSON configs

**During Testing:**
- [ ] All 5 test scenarios completed
- [ ] Logs monitored for errors
- [ ] Performance measured
- [ ] Issues documented

**After Testing:**
- [ ] Test report created
- [ ] Validation gates checked
- [ ] Decision: Deploy or fix issues
- [ ] Next steps documented

---

**Version:** 1.0
**Last Updated:** 2025-10-30
**Author:** Claude AI Assistant
**Status:** ✅ Ready for Local Testing
